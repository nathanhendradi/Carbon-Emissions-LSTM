# -*- coding: utf-8 -*-
"""original Copy of CO2_LSTM Time Series Forecasting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QMTGYtxWcqGcRINI0tdwru37EcE8y5Sc
"""

import tensorflow as tf
import os
import pandas as pd
import numpy as np

#Connect to Google Drive to access CO2 Database
from google.colab import drive
drive.mount('/content/drive')

csv_path = '/content/drive/MyDrive/co2.csv'
df = pd.read_csv(csv_path)

#Limit dataframe to CO2 value colum
co2 = df['Value']

# [[[1], [2], [3], [4], [5]]] [6]
# [[[2], [3], [4], [5], [6]]] [7]
# [[[3], [4], [5], [6], [7]]] [8]

#df_to_X_y function changes dataframe format to X & Y
def df_to_X_y(df, window_size=5):
  df_as_np = df.to_numpy()
  X = []
  y = []
  for i in range(len(df_as_np)-window_size):
    row = [[a] for a in df_as_np[i:i+window_size]]
    X.append(row)
    label = df_as_np[i+window_size]
    y.append(label)
  return np.array(X), np.array(y)

#Set window size to a few datapoints at the time
WINDOW_SIZE = 5

#Convert dataframe to X & y
X1, y1 = df_to_X_y(co2, WINDOW_SIZE)
X1.shape, y1.shape

#split up data into train, validation, and test
X_train1, y_train1 = X1[:200], y1[:200]
X_val1, y_val1 = X1[200:250], y1[200:250]
X_test1, y_test1 = X1[250:], y1[250:]
X_train1.shape, y_train1.shape, X_val1.shape, y_val1.shape, X_test1.shape, y_test1.shape

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import *
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.losses import MeanSquaredError
from tensorflow.keras.metrics import RootMeanSquaredError
from tensorflow.keras.optimizers import Adam

#Create Tensorflow LSTM model using optimized parameters based on GridSearchCV
model1 = Sequential()
model1.add(InputLayer((10, 1)))
model1.add(LSTM(128))
model1.add(Dense(128, 'relu'))
model1.add(Dense(128, 'relu'))
model1.add(Dense(128, 'relu'))
model1.add(Dense(1, 'linear'))

model1.summary()

"""Activation Function: ReLU
Learning Rate (Adam Optimizer): 0.001
LSTM Units: 128
Number of Layers: 3
Number of Neurons per Dense Layer: 128
Window Size: 5

"""

#Save model at checkpoint
cp1 = ModelCheckpoint('model1.keras', save_best_only=True)
#compile model with Adam optimizer
model1.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.001), metrics=[RootMeanSquaredError()])

model1.fit(X_train1, y_train1, validation_data=(X_val1, y_val1), epochs=70, callbacks=[cp1])

#load saved model
from tensorflow.keras.models import load_model
model1 = load_model('model1.keras')

train_predictions = model1.predict(X_train1).flatten()
train_results = pd.DataFrame(data={'Train Predictions':train_predictions, 'Actuals':y_train1})
train_results

import matplotlib.pyplot as plt
plt.plot(train_results['Train Predictions'][50:100])
plt.plot(train_results['Actuals'][50:100])

val_predictions = model1.predict(X_val1).flatten()
val_results = pd.DataFrame(data={'Val Predictions':val_predictions, 'Actuals':y_val1})
val_results

plt.plot(val_results['Val Predictions'][:100])
plt.plot(val_results['Actuals'][:100])

test_predictions = model1.predict(X_test1).flatten()
test_results = pd.DataFrame(data={'Test Predictions':test_predictions, 'Actuals':y_test1})
test_results

plt.plot(test_results['Test Predictions'][:100])
plt.plot(test_results['Actuals'][:100])

from sklearn.metrics import mean_squared_error as mse

def plot_actual_and_predictions(model, X, y, start=0, end=100):
  predictions = model.predict(X).flatten()
  df = pd.DataFrame(data={'Predictions': predictions, 'Actuals':y})
  plt.plot(df['Predictions'][start:end])
  plt.plot(df['Actuals'][start:end])
  return df, mse(predictions, y)

plot_actual_and_predictions(model1, X_test1, y_test1)

from sklearn.model_selection import GridSearchCV

def create_model(activation_function, num_neurons, lstm_units, window_size, num_layers, adam_learning_rate):
  #data preprocessing
  X1, y1 = df_to_X_y(co2, window_size)
  X1.shape, y1.shape
  X_train1, y_train1 = X1[:200], y1[:200]
  X_val1, y_val1 = X1[200:250], y1[200:250]
  X_test1, y_test1 = X1[250:], y1[250:]
  X_train1.shape, y_train1.shape, X_val1.shape, y_val1.shape, X_test1.shape, y_test1.shape

  model1 = Sequential()
  model1.add(InputLayer((window_size, 1)))
  model1.add(LSTM(lstm_units))
  for layer in range(num_layers):
    model1.add(Dense(num_neurons, activation_function))
  model1.add(Dense(1, 'linear'))

  model1.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=adam_learning_rate), metrics=[RootMeanSquaredError()])
  return X_train1, y_train1, X_val1, y_val1, X_test1, y_test1, model1

param_grid = {
    'activation_function': ['relu', 'tanh'],
    'num_neurons': [64, 128],
    'lstm_units': [64, 128],
    'window_size': [5, 10, 20],
    'num_layers': [1, 2, 3, 4],
    'adam_learning_rate': [0.001, 0.0001]
}

model = create_model('relu', 64, 64, 5, 1, 0.001)

grid = GridSearchCV(estimator=model, param_grid=param_grid)
grid_result = grid.fit(X_train1, y_train1)